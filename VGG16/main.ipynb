{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pydot\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from contextlib import redirect_stdout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) With functional api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(input_shape = None, classes = None):\n",
    "    if input_shape and classes is not None:\n",
    "        input_data = tf.keras.layers.Input(shape=input_shape)\n",
    "        # First Convolutional block\n",
    "        conv1_1 = tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(input_data)\n",
    "        conv1_2 = tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv1_1)\n",
    "        maxpool_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(conv1_2)\n",
    "        \n",
    "        # Second Convolution Block\n",
    "        conv2_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(maxpool_1)\n",
    "        conv2_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv2_1)\n",
    "        maxpool_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(conv2_2)\n",
    "        \n",
    "        # Third Convolution Block\n",
    "        conv3_1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(maxpool_2)\n",
    "        conv3_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv3_1)\n",
    "        conv3_3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv3_2)\n",
    "        maxpool_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(conv3_3)\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        conv4_1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(maxpool_3)\n",
    "        conv4_2 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv4_1)\n",
    "        conv4_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv4_2)\n",
    "        maxpool_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(conv4_3)\n",
    "        \n",
    "        # Fifth Convolutional Block\n",
    "        conv5_1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(maxpool_4)\n",
    "        conv5_2 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv5_1)\n",
    "        conv5_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")(conv5_2)\n",
    "        maxpool_5 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(conv5_3)\n",
    "        \n",
    "        # Flatten\n",
    "        flatten = tf.keras.layers.Flatten()(maxpool_5)\n",
    "        fc1 = tf.keras.layers.Dense(4096, activation='relu')(flatten)\n",
    "        fc2 = tf.keras.layers.Dense(4096, activation='relu')(fc1)\n",
    "        \n",
    "        output_data = tf.keras.layers.Dense(classes, activation='softmax')(fc2)\n",
    "        \n",
    "        model = tf.keras.models.Model(inputs = input_data, outputs = output_data)\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " def summary(output=None, target=None, model = None):\n",
    "        \"\"\" Show / Save model structure (summary) \"\"\"\n",
    "        if model is not None:\n",
    "            model.summary()\n",
    "            if target is not None:\n",
    "                os.makedirs(output, exist_ok=True)\n",
    "                with open(os.path.join(output, target), \"w\") as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 224, 224, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 112, 112, 128)     73856     \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 112, 112, 128)     147584    \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 56, 56, 256)       295168    \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 56, 56, 256)       590080    \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 56, 56, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 28, 28, 256)       0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 14, 14, 512)       0         \n_________________________________________________________________\nconv2d_23 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 4096)              102764544 \n_________________________________________________________________\ndense_5 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\ndense_6 (Dense)              (None, 1000)              4097000   \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = vgg16(input_shape=(224, 224, 3), classes = 1000)\n",
    "summary(output= './summary', target='summary', model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Model visual_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_plot(model = None, file_name=None):\n",
    "    if model and file_name is not None:\n",
    "        print('Model plotting...')\n",
    "        \n",
    "        plot_model(model, to_file = file_name, show_shapes=True,\n",
    "                   show_layer_names=True,\n",
    "                   rankdir='TB', expand_nested=True, dpi=96)\n",
    "        print('Model plotted..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model plotting...\nModel plotted..\n"
    }
   ],
   "source": [
    "model_plot(model = model, file_name='vgg16_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    train_dataset = h5py.File('dataset/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('dataset/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_x_orig, train_y, test_x_orig, test_y, classes = preprocessing()\n",
    "    \n",
    "    # Standardize data to have feature values between 0 and 1.\n",
    "    train_x = train_x_orig/255.\n",
    "    test_x = test_x_orig/255.\n",
    "    \n",
    "    train_y = to_categorical(train_y)\n",
    "    test_y = to_categorical(test_y)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(train_x[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(train_y[i])\n",
    "    plt.show()\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'dataset/train_signs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ed48cf235ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-1de4687bcfa3>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_x_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Standardize data to have feature values between 0 and 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-1de4687bcfa3>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/train_signs.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_set_x_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_set_x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# your train set features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_set_y_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_set_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# your train set labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'dataset/train_signs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = load_data()\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Custom_Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Custom dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, units=32, initializer=None):\n",
    "    super(Dense, self).__init__()\n",
    "    self.units = units\n",
    "    self.initializer = initializer\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    w_init = self.initializer\n",
    "    self.w = tf.Variable(initial_value=w_init(shape=(input_shape[-1], self.units),\n",
    "                         dtype='float32'),trainable=True)\n",
    "    b_init = self.initializer\n",
    "    self.b = tf.Variable(initial_value=b_init(shape=(self.units,),\n",
    "                         dtype='float32'),trainable=True)\n",
    "   \n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "  def get_config(self):\n",
    "    config = super(Dense, self).get_config()\n",
    "    config.update({'units': self.units})\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2, 80)\n"
    }
   ],
   "source": [
    "dense = Dense(units = 80, initializer = tf.initializers.GlorotUniform())\n",
    "x = tf.ones((2, 2))\n",
    "y = dense(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "weights: 2\ntrainable weights: 2\n"
    }
   ],
   "source": [
    "print('weights:', len(dense.weights))\n",
    "print('trainable weights:', len(dense.trainable_weights))  # w and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 80}"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "config = dense.get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Custom dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(Dropout, self).__init__(**kwargs)\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2, 80)\n"
    }
   ],
   "source": [
    "dropout = Dropout(0.5)\n",
    "y = dropout(y, training=True)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, inputShape, classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.inputShape = inputShape\n",
    "        self.classes = classes\n",
    "        \n",
    "        # First Convolutional block\n",
    "        self.conv1_1 = tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),\n",
    "                                         input_shape=inputShape,padding=\"same\",\n",
    "                                         activation=\"relu\")\n",
    "        self.conv1_2 = tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.maxpool_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n",
    "        \n",
    "        # Second Convolution Block\n",
    "        self.conv2_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.conv2_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.maxpool_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n",
    "        \n",
    "        # Third Convolution Block\n",
    "        self.conv3_1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.conv3_2 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.conv3_3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.maxpool_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        self.conv4_1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.conv4_2 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.conv4_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        \n",
    "        self.maxpool_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n",
    "        \n",
    "        # Fifth Convolutional Block\n",
    "        self.conv5_1 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        self.conv5_2 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        self.conv5_3 = tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3),\n",
    "                                         padding=\"same\", activation=\"relu\")\n",
    "        self.maxpool_5 = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n",
    "        \n",
    "        # Flatten\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.fc1 = Dense(units=4096, initializer=tf.initializers.GlorotUniform())\n",
    "        self.act1 = tf.keras.layers.ReLU()\n",
    "        self.drop1 = Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = Dense(units=4096, initializer=tf.initializers.GlorotUniform())\n",
    "        self.act2 = tf.keras.layers.ReLU()\n",
    "        self.drop2 = Dropout(0.5)\n",
    "        \n",
    "        self.output_data = Dense(units=self.classes, initializer=tf.initializers.GlorotUniform())\n",
    "        self.act3 = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, x):\n",
    "        # First\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        \n",
    "        # Second Convolution Block\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        \n",
    "        # Third Convolution Block\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.maxpool_3(x)\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.maxpool_4(x)\n",
    "        \n",
    "        # Fifth Convolutional Block\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = self.conv5_3(x)\n",
    "        x = self.maxpool_5(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.drop1(x, training=True)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.drop2(x, training=True)\n",
    "        \n",
    "        x = self.output_data(x)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 1000\n",
    "m = Model(input_shape, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom_Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 224, 224, 3)\n",
    "m.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_26 (Conv2D)           multiple                  1792      \n_________________________________________________________________\nconv2d_27 (Conv2D)           multiple                  36928     \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling multiple                  0         \n_________________________________________________________________\nconv2d_28 (Conv2D)           multiple                  73856     \n_________________________________________________________________\nconv2d_29 (Conv2D)           multiple                  147584    \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling multiple                  0         \n_________________________________________________________________\nconv2d_30 (Conv2D)           multiple                  295168    \n_________________________________________________________________\nconv2d_31 (Conv2D)           multiple                  590080    \n_________________________________________________________________\nconv2d_32 (Conv2D)           multiple                  590080    \n_________________________________________________________________\nmax_pooling2d_12 (MaxPooling multiple                  0         \n_________________________________________________________________\nconv2d_33 (Conv2D)           multiple                  1180160   \n_________________________________________________________________\nconv2d_34 (Conv2D)           multiple                  2359808   \n_________________________________________________________________\nconv2d_35 (Conv2D)           multiple                  2359808   \n_________________________________________________________________\nmax_pooling2d_13 (MaxPooling multiple                  0         \n_________________________________________________________________\nconv2d_36 (Conv2D)           multiple                  2359808   \n_________________________________________________________________\nconv2d_37 (Conv2D)           multiple                  2359808   \n_________________________________________________________________\nconv2d_38 (Conv2D)           multiple                  2359808   \n_________________________________________________________________\nmax_pooling2d_14 (MaxPooling multiple                  0         \n_________________________________________________________________\nflatten_2 (Flatten)          multiple                  0         \n_________________________________________________________________\ndense_8 (Dense)              multiple                  102764544 \n_________________________________________________________________\nre_lu (ReLU)                 multiple                  0         \n_________________________________________________________________\ndropout_1 (Dropout)          multiple                  0         \n_________________________________________________________________\ndense_9 (Dense)              multiple                  16781312  \n_________________________________________________________________\nre_lu_1 (ReLU)               multiple                  0         \n_________________________________________________________________\ndropout_2 (Dropout)          multiple                  0         \n_________________________________________________________________\ndense_10 (Dense)             multiple                  4097000   \n_________________________________________________________________\nsoftmax (Softmax)            multiple                  0         \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "summary(output= './summary', target='custom_model_summary', model = m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self):\n",
    "        self.loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        self.train_loss = tf.keras.metrics.Mean(name= 'train_loss')\n",
    "        self.train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "        self.test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "        self.test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "        self.model = Model((224,224, 3),1000)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs, outputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(inputs, training=True)\n",
    "            loss = self.loss(outputs, predictions)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        self.train_loss(loss)\n",
    "        self.train_accuracy(outputs, predictions)\n",
    "\n",
    "\n",
    "        \n",
    "    @tf.function\n",
    "    def test_step(self, inputs, outputs):\n",
    "        predictions = self.model(inputs)\n",
    "        t_loss = self.loss(outputs, predictions)\n",
    "        self.test_loss(t_loss)\n",
    "        self.test_accuracy(outputs, predictions)\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self, epochs=1, train_ds = None, test_ds = None):\n",
    "        for epoch in range(epochs):\n",
    "            for inputs, outputs in train_ds:\n",
    "                self.train_step(inputs, outputs)\n",
    "\n",
    "            for test_inputs, test_outputs in test_ds:\n",
    "                self.test_step(test_inputs, test_outputs)\n",
    "\n",
    "\n",
    "\n",
    "            template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy:{}'\n",
    "            print(template.format(epoch+1,self.train_loss.result(),self.train_accuracy.result()*100,self.test_loss.result(),self.test_accuracy.result()*100))\n",
    "\n",
    "        self.train_loss.reset_states()\n",
    "        self.train_accuracy.reset_states()\n",
    "        self.test_loss.reset_states()\n",
    "        self.test_accuracy.reset_states()\n",
    "\n",
    "\n",
    "    def save(self, name='', save_format='tf'):\n",
    "        self.model.save(name, save_format=save_format)\n",
    "        return \"Your model saved\"\n",
    "        \n",
    "\n",
    "    def predict(self, input):\n",
    "        prediction = self.model.predict(input)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18-candidate"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}